{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuBMqgG095jbjZZQleTQdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sprprathiba/NLP/blob/main/NLP_Day2_Bagofwords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEXT PREPROCESSING**"
      ],
      "metadata": {
        "id": "gvc4BLxrWhre"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCj_Hkc8VgJI",
        "outputId": "e013545d-540b-4b05-d8a1-36c84c1259e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"\n",
        "Python was invented in the late 1980s[41] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL,[42] capable of exception handling and interfacing with the Amoeba operating system.[11] Its implementation began in December 1989.[43] Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python's \"benevolent dictator for life\" (BDFL), a title the Python community bestowed upon him to reflect his long-term commitment as the project's chief decision-maker[44] (he's since come out of retirement and is self-titled \"BDFL-emeritus\"). In January 2019, active Python core developers elected a five-member Steering Council to lead the project.[45][46]\n",
        "\n",
        "Python 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support.[47] Python 3.0, released on 3 December 2008, with many of its major features backported to Python 2.6.x[48] and 2.7.x. Releases of Python 3 include the 2to3 utility, which automates the translation of Python 2 code to Python 3.[49]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JAKSu7trVkVI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 1. CONVERTING INTO SENTENCES**"
      ],
      "metadata": {
        "id": "yU8CjDGpYAW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "6NUmXVyiVwl5",
        "outputId": "3f6c5244-2437-4aca-caf3-8400a6576e24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPython was invented in the late 1980s[41] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL,[42] capable of exception handling and interfacing with the Amoeba operating system.[11] Its implementation began in December 1989.[43] Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python\\'s \"benevolent dictator for life\" (BDFL), a title the Python community bestowed upon him to reflect his long-term commitment as the project\\'s chief decision-maker[44] (he\\'s since come out of retirement and is self-titled \"BDFL-emeritus\"). In January 2019, active Python core developers elected a five-member Steering Council to lead the project.[45][46]\\n\\nPython 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support.[47] Python 3.0, released on 3 December 2008, with many of its major features backported to Python 2.6.x[48] and 2.7.x. Releases of Python 3 include the 2to3 utility, which automates the translation of Python 2 code to Python 3.[49]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. CLEANING THE WORDS**"
      ],
      "metadata": {
        "id": "NZUI3H5wYHAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Tokenization ---- converting paragraph into sentences*"
      ],
      "metadata": {
        "id": "_a3Sw-J4Zfmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "RROfMFKFZksP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*To use sent_tokenize we need to download one package called punkt*"
      ],
      "metadata": {
        "id": "E36xavG1aK0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRPaA7QaZ8rG",
        "outputId": "965d2549-74c6-4fbe-ecaf-df05bd3399f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuML84Rsad_J",
        "outputId": "0901637d-aea5-471d-8563-c6f143bf8612"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***3. STEMMING AND LEMMATIZATION***"
      ],
      "metadata": {
        "id": "NzJ9PPsLavhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmer.stem('history')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "soU9a7XJatGM",
        "outputId": "9847e98a-5ae4-4107-e5b5-5ece7cd97d2c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'histori'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*To use Lemmatizer we need to download package called wordnet*"
      ],
      "metadata": {
        "id": "xJa21fJwbtpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "lemmatizer.lemmatize('history')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "oe51QeUSbA-v",
        "outputId": "98e8e9bf-6901-4d6b-ea9c-e0543c7d4493"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'history'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*REMOVING UNWANTED SYMBOLS like special characters*"
      ],
      "metadata": {
        "id": "q2475L9zY3ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "ydcVoz72YLI6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "  clean_words = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "  clean_words = clean_words.lower()\n",
        "  corpus.append(clean_words)\n",
        "\n"
      ],
      "metadata": {
        "id": "V_SW9rzEY-kT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlg9UjcHdK1a",
        "outputId": "a14bfc8b-5237-434c-9a60-0720760ee5b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' python was invented in the late     s     by guido van rossum at centrum wiskunde   informatica  cwi  in the netherlands as a successor to the abc programming language  which was inspired by setl      capable of exception handling and interfacing with the amoeba operating system ',\n",
              " '     its implementation began in december      ',\n",
              " '     van rossum shouldered sole responsibility for the project  as the lead developer  until    july       when he announced his  permanent vacation  from his responsibilities as python s  benevolent dictator for life   bdfl   a title the python community bestowed upon him to reflect his long term commitment as the project s chief decision maker      he s since come out of retirement and is self titled  bdfl emeritus   ',\n",
              " 'in january       active python core developers elected a five member steering council to lead the project ',\n",
              " '          python     was released on    october       with many major new features such as list comprehensions  cycle detecting garbage collection  reference counting  and unicode support ',\n",
              " '     python      released on   december       with many of its major features backported to python     x     and     x ',\n",
              " 'releases of python   include the  to  utility  which automates the translation of python   code to python   ',\n",
              " '    ']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to proceed with stopwords\n",
        "# To use stopwords need to download package called stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords.words('english')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dfEpkJWfI8O",
        "outputId": "ed568692-a666-4b3a-bf15-52b470e09c88"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Stemming\n",
        "\n",
        "for i in corpus:\n",
        "  # print(i) #sentence\n",
        "  words=nltk.word_tokenize(i) #This will convert sentence into the words\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMCvN1dFdmCN",
        "outputId": "f3338580-66df-482a-9106-97cc5aac8fb3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python\n",
            "invent\n",
            "late\n",
            "guido\n",
            "van\n",
            "rossum\n",
            "centrum\n",
            "wiskund\n",
            "informatica\n",
            "cwi\n",
            "netherland\n",
            "successor\n",
            "abc\n",
            "program\n",
            "languag\n",
            "inspir\n",
            "setl\n",
            "capabl\n",
            "except\n",
            "handl\n",
            "interfac\n",
            "amoeba\n",
            "oper\n",
            "system\n",
            "implement\n",
            "began\n",
            "decemb\n",
            "van\n",
            "rossum\n",
            "shoulder\n",
            "sole\n",
            "respons\n",
            "project\n",
            "lead\n",
            "develop\n",
            "juli\n",
            "announc\n",
            "perman\n",
            "vacat\n",
            "respons\n",
            "python\n",
            "benevol\n",
            "dictat\n",
            "life\n",
            "bdfl\n",
            "titl\n",
            "python\n",
            "commun\n",
            "bestow\n",
            "upon\n",
            "reflect\n",
            "long\n",
            "term\n",
            "commit\n",
            "project\n",
            "chief\n",
            "decis\n",
            "maker\n",
            "sinc\n",
            "come\n",
            "retir\n",
            "self\n",
            "titl\n",
            "bdfl\n",
            "emeritu\n",
            "januari\n",
            "activ\n",
            "python\n",
            "core\n",
            "develop\n",
            "elect\n",
            "five\n",
            "member\n",
            "steer\n",
            "council\n",
            "lead\n",
            "project\n",
            "python\n",
            "releas\n",
            "octob\n",
            "mani\n",
            "major\n",
            "new\n",
            "featur\n",
            "list\n",
            "comprehens\n",
            "cycl\n",
            "detect\n",
            "garbag\n",
            "collect\n",
            "refer\n",
            "count\n",
            "unicod\n",
            "support\n",
            "python\n",
            "releas\n",
            "decemb\n",
            "mani\n",
            "major\n",
            "featur\n",
            "backport\n",
            "python\n",
            "x\n",
            "x\n",
            "releas\n",
            "python\n",
            "includ\n",
            "util\n",
            "autom\n",
            "translat\n",
            "python\n",
            "code\n",
            "python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Lemmatization\n",
        "\n",
        "for i in corpus:\n",
        "  # print(i) #sentence\n",
        "  words=nltk.word_tokenize(i) #This will convert sentence into the words\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev8zIIc2fuHI",
        "outputId": "56b022ac-7616-4097-c456-ac11a317a7c7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python\n",
            "invented\n",
            "late\n",
            "guido\n",
            "van\n",
            "rossum\n",
            "centrum\n",
            "wiskunde\n",
            "informatica\n",
            "cwi\n",
            "netherlands\n",
            "successor\n",
            "abc\n",
            "programming\n",
            "language\n",
            "inspired\n",
            "setl\n",
            "capable\n",
            "exception\n",
            "handling\n",
            "interfacing\n",
            "amoeba\n",
            "operating\n",
            "system\n",
            "implementation\n",
            "began\n",
            "december\n",
            "van\n",
            "rossum\n",
            "shouldered\n",
            "sole\n",
            "responsibility\n",
            "project\n",
            "lead\n",
            "developer\n",
            "july\n",
            "announced\n",
            "permanent\n",
            "vacation\n",
            "responsibility\n",
            "python\n",
            "benevolent\n",
            "dictator\n",
            "life\n",
            "bdfl\n",
            "title\n",
            "python\n",
            "community\n",
            "bestowed\n",
            "upon\n",
            "reflect\n",
            "long\n",
            "term\n",
            "commitment\n",
            "project\n",
            "chief\n",
            "decision\n",
            "maker\n",
            "since\n",
            "come\n",
            "retirement\n",
            "self\n",
            "titled\n",
            "bdfl\n",
            "emeritus\n",
            "january\n",
            "active\n",
            "python\n",
            "core\n",
            "developer\n",
            "elected\n",
            "five\n",
            "member\n",
            "steering\n",
            "council\n",
            "lead\n",
            "project\n",
            "python\n",
            "released\n",
            "october\n",
            "many\n",
            "major\n",
            "new\n",
            "feature\n",
            "list\n",
            "comprehension\n",
            "cycle\n",
            "detecting\n",
            "garbage\n",
            "collection\n",
            "reference\n",
            "counting\n",
            "unicode\n",
            "support\n",
            "python\n",
            "released\n",
            "december\n",
            "many\n",
            "major\n",
            "feature\n",
            "backported\n",
            "python\n",
            "x\n",
            "x\n",
            "release\n",
            "python\n",
            "include\n",
            "utility\n",
            "automates\n",
            "translation\n",
            "python\n",
            "code\n",
            "python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONVERTING WORDS INTO VECTORS USING BAG OF WORDS**"
      ],
      "metadata": {
        "id": "o34M-BoygYhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "for i in range(len(sentences)):\n",
        "  clean_words = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "  clean_words = clean_words.lower().split()\n",
        "  clean_words = [lemmatizer.lemmatize(word) for word in clean_words if word not in set(stopwords.words('english'))]\n",
        "  # print(clean_words)\n",
        "  final_words = ' '.join(clean_words)\n",
        "  corpus.append(final_words)"
      ],
      "metadata": {
        "id": "hJwuwodxlt7H"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(binary=True) #why binary=True then only we will not get binary as 2, 4 in array"
      ],
      "metadata": {
        "id": "hHqSXIiighmo"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = cv.fit_transform(corpus)\n",
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZIM36PhkQEd",
        "outputId": "fcbd8727-82e4-44d6-afe1-ae6985e290e9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'python': 62,\n",
              " 'invented': 42,\n",
              " 'late': 46,\n",
              " 'guido': 35,\n",
              " 'van': 87,\n",
              " 'rossum': 69,\n",
              " 'centrum': 11,\n",
              " 'wiskunde': 88,\n",
              " 'informatica': 39,\n",
              " 'cwi': 22,\n",
              " 'netherlands': 55,\n",
              " 'successor': 76,\n",
              " 'abc': 0,\n",
              " 'programming': 60,\n",
              " 'language': 45,\n",
              " 'inspired': 40,\n",
              " 'setl': 71,\n",
              " 'capable': 10,\n",
              " 'exception': 31,\n",
              " 'handling': 36,\n",
              " 'interfacing': 41,\n",
              " 'amoeba': 2,\n",
              " 'operating': 58,\n",
              " 'system': 78,\n",
              " 'implementation': 37,\n",
              " 'began': 7,\n",
              " 'december': 24,\n",
              " 'shouldered': 72,\n",
              " 'sole': 74,\n",
              " 'responsibility': 67,\n",
              " 'project': 61,\n",
              " 'lead': 47,\n",
              " 'developer': 27,\n",
              " 'july': 44,\n",
              " 'announced': 3,\n",
              " 'permanent': 59,\n",
              " 'vacation': 86,\n",
              " 'benevolent': 8,\n",
              " 'dictator': 28,\n",
              " 'life': 48,\n",
              " 'bdfl': 6,\n",
              " 'title': 80,\n",
              " 'community': 17,\n",
              " 'bestowed': 9,\n",
              " 'upon': 84,\n",
              " 'reflect': 64,\n",
              " 'long': 50,\n",
              " 'term': 79,\n",
              " 'commitment': 16,\n",
              " 'chief': 12,\n",
              " 'decision': 25,\n",
              " 'maker': 52,\n",
              " 'since': 73,\n",
              " 'come': 15,\n",
              " 'retirement': 68,\n",
              " 'self': 70,\n",
              " 'titled': 81,\n",
              " 'emeritus': 30,\n",
              " 'january': 43,\n",
              " 'active': 1,\n",
              " 'core': 19,\n",
              " 'elected': 29,\n",
              " 'five': 33,\n",
              " 'member': 54,\n",
              " 'steering': 75,\n",
              " 'council': 20,\n",
              " 'released': 66,\n",
              " 'october': 57,\n",
              " 'many': 53,\n",
              " 'major': 51,\n",
              " 'new': 56,\n",
              " 'feature': 32,\n",
              " 'list': 49,\n",
              " 'comprehension': 18,\n",
              " 'cycle': 23,\n",
              " 'detecting': 26,\n",
              " 'garbage': 34,\n",
              " 'collection': 14,\n",
              " 'reference': 63,\n",
              " 'counting': 21,\n",
              " 'unicode': 83,\n",
              " 'support': 77,\n",
              " 'backported': 5,\n",
              " 'release': 65,\n",
              " 'include': 38,\n",
              " 'utility': 85,\n",
              " 'automates': 4,\n",
              " 'translation': 82,\n",
              " 'code': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Kg0MAWOinI6w",
        "outputId": "ca39a50a-9f34-4987-e484-8b3c16d559dd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'python invented late guido van rossum centrum wiskunde informatica cwi netherlands successor abc programming language inspired setl capable exception handling interfacing amoeba operating system'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b_zbBNLkqJM",
        "outputId": "78d064fd-6330-4c1c-c9df-40816e30246d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}